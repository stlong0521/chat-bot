from __future__ import division
from nltk import word_tokenize

def tokenize(sentence):
    return word_tokenize(sentence)
